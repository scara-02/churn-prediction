{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "data=pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocess the data\n",
    "### Drop irrelevant columns\n",
    "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France       0   42       2       0.00              1   \n",
       "1             608     Spain       0   41       1   83807.86              1   \n",
       "2             502    France       0   42       8  159660.80              3   \n",
       "3             699    France       0   39       1       0.00              2   \n",
       "4             850     Spain       0   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France       1   39       5       0.00              2   \n",
       "9996          516    France       1   35      10   57369.61              1   \n",
       "9997          709    France       0   36       7       0.00              1   \n",
       "9998          772   Germany       1   42       3   75075.31              2   \n",
       "9999          792    France       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encode categorical variables\n",
    "label_encoder_gender=LabelEncoder()\n",
    "data['Gender']=label_encoder_gender.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Onehot encode 'Geography\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder_geo=OneHotEncoder()\n",
    "geo_encoder=onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder_geo.get_feature_names_out(['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_encoded_df=pd.DataFrame(geo_encoder,columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Combine one hot encoder columns with the original data\n",
    "data=pd.concat([data.drop('Geography',axis=1),geo_encoded_df],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the encoders and sscaler\n",
    "with open('label_encoder_gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl','wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1               1.0   \n",
       "1               1        112542.58       0               0.0   \n",
       "2               0        113931.57       1               1.0   \n",
       "3               0         93826.63       0               1.0   \n",
       "4               1         79084.10       0               0.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                0.0              0.0  \n",
       "1                0.0              1.0  \n",
       "2                0.0              0.0  \n",
       "3                0.0              0.0  \n",
       "4                0.0              1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DiVide the dataset into indepent and dependent features\n",
    "X=data.drop('Exited',axis=1)\n",
    "y=data['Exited']\n",
    "\n",
    "## Split the data in training and tetsing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "## Scale these features\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35649971,  0.91324755, -0.6557859 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [-0.20389777,  0.91324755,  0.29493847, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802],\n",
       "       [-0.96147213,  0.91324755, -1.41636539, ..., -0.99850112,\n",
       "        -0.57946723,  1.73494238],\n",
       "       ...,\n",
       "       [ 0.86500853, -1.09499335, -0.08535128, ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.15932282,  0.91324755,  0.3900109 , ...,  1.00150113,\n",
       "        -0.57946723, -0.57638802],\n",
       "       [ 0.47065475,  0.91324755,  1.15059039, ..., -0.99850112,\n",
       "         1.72572313, -0.57638802]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       0   42       2       0.00              1          1   \n",
       "1             608       0   41       1   83807.86              1          0   \n",
       "2             502       0   42       8  159660.80              3          1   \n",
       "3             699       0   39       1       0.00              2          0   \n",
       "4             850       0   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       1   39       5       0.00              2          1   \n",
       "9996          516       1   35      10   57369.61              1          1   \n",
       "9997          709       0   36       7       0.00              1          0   \n",
       "9998          772       1   42       3   75075.31              2          1   \n",
       "9999          792       0   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1               1.0   \n",
       "1                  1        112542.58       0               0.0   \n",
       "2                  0        113931.57       1               1.0   \n",
       "3                  0         93826.63       0               1.0   \n",
       "4                  1         79084.10       0               0.0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0               1.0   \n",
       "9996               1        101699.77       0               1.0   \n",
       "9997               1         42085.58       1               1.0   \n",
       "9998               0         92888.52       1               0.0   \n",
       "9999               0         38190.78       0               1.0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                   0.0              0.0  \n",
       "1                   0.0              1.0  \n",
       "2                   0.0              0.0  \n",
       "3                   0.0              0.0  \n",
       "4                   0.0              1.0  \n",
       "...                 ...              ...  \n",
       "9995                0.0              0.0  \n",
       "9996                0.0              0.0  \n",
       "9997                0.0              0.0  \n",
       "9998                1.0              0.0  \n",
       "9999                0.0              0.0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Build Our ANN Model\n",
    "model=Sequential([\n",
    "    Dense(64,activation='relu',input_shape=(X_train.shape[1],)), ## HL1 Connected wwith input layer\n",
    "    Dense(32,activation='relu'), ## HL2\n",
    "    Dense(1,activation='sigmoid')  ## output layer\n",
    "]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.losses.BinaryCrossentropy at 0x25bff1eb2d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss=tensorflow.keras.losses.BinaryCrossentropy()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile the model\n",
    "model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the Tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up Early Stopping\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=300,restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8679 - val_loss: 0.3501 - val_accuracy: 0.8640\n",
      "Epoch 2/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8674 - val_loss: 0.3373 - val_accuracy: 0.8645\n",
      "Epoch 3/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8684 - val_loss: 0.3450 - val_accuracy: 0.8605\n",
      "Epoch 4/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8710 - val_loss: 0.3435 - val_accuracy: 0.8625\n",
      "Epoch 5/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8712 - val_loss: 0.3546 - val_accuracy: 0.8680\n",
      "Epoch 6/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8694 - val_loss: 0.3487 - val_accuracy: 0.8630\n",
      "Epoch 7/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8706 - val_loss: 0.3571 - val_accuracy: 0.8635\n",
      "Epoch 8/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8714 - val_loss: 0.3636 - val_accuracy: 0.8590\n",
      "Epoch 9/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8717 - val_loss: 0.3539 - val_accuracy: 0.8635\n",
      "Epoch 10/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8742 - val_loss: 0.3753 - val_accuracy: 0.8630\n",
      "Epoch 11/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8756 - val_loss: 0.3594 - val_accuracy: 0.8595\n",
      "Epoch 12/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8760 - val_loss: 0.3548 - val_accuracy: 0.8585\n",
      "Epoch 13/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8758 - val_loss: 0.3691 - val_accuracy: 0.8610\n",
      "Epoch 14/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8785 - val_loss: 0.3642 - val_accuracy: 0.8580\n",
      "Epoch 15/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8765 - val_loss: 0.3724 - val_accuracy: 0.8525\n",
      "Epoch 16/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8741 - val_loss: 0.3616 - val_accuracy: 0.8550\n",
      "Epoch 17/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8770 - val_loss: 0.3735 - val_accuracy: 0.8535\n",
      "Epoch 18/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8781 - val_loss: 0.3524 - val_accuracy: 0.8605\n",
      "Epoch 19/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8776 - val_loss: 0.3524 - val_accuracy: 0.8630\n",
      "Epoch 20/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8798 - val_loss: 0.3664 - val_accuracy: 0.8610\n",
      "Epoch 21/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8780 - val_loss: 0.3803 - val_accuracy: 0.8575\n",
      "Epoch 22/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.8783 - val_loss: 0.3711 - val_accuracy: 0.8565\n",
      "Epoch 23/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8815 - val_loss: 0.3793 - val_accuracy: 0.8575\n",
      "Epoch 24/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8808 - val_loss: 0.3754 - val_accuracy: 0.8560\n",
      "Epoch 25/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8805 - val_loss: 0.3751 - val_accuracy: 0.8500\n",
      "Epoch 26/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2771 - accuracy: 0.8801 - val_loss: 0.3783 - val_accuracy: 0.8480\n",
      "Epoch 27/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.8866 - val_loss: 0.3955 - val_accuracy: 0.8510\n",
      "Epoch 28/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8816 - val_loss: 0.3933 - val_accuracy: 0.8495\n",
      "Epoch 29/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.8842 - val_loss: 0.3945 - val_accuracy: 0.8540\n",
      "Epoch 30/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8860 - val_loss: 0.3846 - val_accuracy: 0.8570\n",
      "Epoch 31/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8824 - val_loss: 0.4047 - val_accuracy: 0.8530\n",
      "Epoch 32/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8884 - val_loss: 0.4324 - val_accuracy: 0.8500\n",
      "Epoch 33/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8869 - val_loss: 0.4149 - val_accuracy: 0.8570\n",
      "Epoch 34/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.8867 - val_loss: 0.4168 - val_accuracy: 0.8500\n",
      "Epoch 35/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8876 - val_loss: 0.4320 - val_accuracy: 0.8465\n",
      "Epoch 36/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8909 - val_loss: 0.4193 - val_accuracy: 0.8475\n",
      "Epoch 37/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8910 - val_loss: 0.4502 - val_accuracy: 0.8545\n",
      "Epoch 38/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8903 - val_loss: 0.4425 - val_accuracy: 0.8495\n",
      "Epoch 39/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8885 - val_loss: 0.4204 - val_accuracy: 0.8485\n",
      "Epoch 40/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8898 - val_loss: 0.4554 - val_accuracy: 0.8480\n",
      "Epoch 41/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8914 - val_loss: 0.4358 - val_accuracy: 0.8515\n",
      "Epoch 42/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8939 - val_loss: 0.4719 - val_accuracy: 0.8445\n",
      "Epoch 43/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8926 - val_loss: 0.4817 - val_accuracy: 0.8435\n",
      "Epoch 44/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8929 - val_loss: 0.4973 - val_accuracy: 0.8415\n",
      "Epoch 45/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8925 - val_loss: 0.4836 - val_accuracy: 0.8395\n",
      "Epoch 46/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.8925 - val_loss: 0.4767 - val_accuracy: 0.8485\n",
      "Epoch 47/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8931 - val_loss: 0.4578 - val_accuracy: 0.8455\n",
      "Epoch 48/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8931 - val_loss: 0.4700 - val_accuracy: 0.8475\n",
      "Epoch 49/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8949 - val_loss: 0.4881 - val_accuracy: 0.8440\n",
      "Epoch 50/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2326 - accuracy: 0.8992 - val_loss: 0.4749 - val_accuracy: 0.8450\n",
      "Epoch 51/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2285 - accuracy: 0.8982 - val_loss: 0.5120 - val_accuracy: 0.8510\n",
      "Epoch 52/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.8969 - val_loss: 0.5178 - val_accuracy: 0.8460\n",
      "Epoch 53/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.8967 - val_loss: 0.5063 - val_accuracy: 0.8385\n",
      "Epoch 54/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2277 - accuracy: 0.8974 - val_loss: 0.5277 - val_accuracy: 0.8460\n",
      "Epoch 55/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.8960 - val_loss: 0.5252 - val_accuracy: 0.8390\n",
      "Epoch 56/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.8954 - val_loss: 0.5327 - val_accuracy: 0.8475\n",
      "Epoch 57/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.8945 - val_loss: 0.5204 - val_accuracy: 0.8390\n",
      "Epoch 58/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2320 - accuracy: 0.8954 - val_loss: 0.5492 - val_accuracy: 0.8290\n",
      "Epoch 59/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.8969 - val_loss: 0.5338 - val_accuracy: 0.8510\n",
      "Epoch 60/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8980 - val_loss: 0.5504 - val_accuracy: 0.8425\n",
      "Epoch 61/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.8988 - val_loss: 0.5486 - val_accuracy: 0.8385\n",
      "Epoch 62/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9003 - val_loss: 0.5217 - val_accuracy: 0.8425\n",
      "Epoch 63/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2179 - accuracy: 0.9000 - val_loss: 0.5709 - val_accuracy: 0.8495\n",
      "Epoch 64/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9001 - val_loss: 0.5517 - val_accuracy: 0.8470\n",
      "Epoch 65/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.8978 - val_loss: 0.5779 - val_accuracy: 0.8435\n",
      "Epoch 66/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9004 - val_loss: 0.5909 - val_accuracy: 0.8365\n",
      "Epoch 67/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9005 - val_loss: 0.5916 - val_accuracy: 0.8425\n",
      "Epoch 68/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9041 - val_loss: 0.5893 - val_accuracy: 0.8360\n",
      "Epoch 69/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.8979 - val_loss: 0.5662 - val_accuracy: 0.8445\n",
      "Epoch 70/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2163 - accuracy: 0.9039 - val_loss: 0.5956 - val_accuracy: 0.8475\n",
      "Epoch 71/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9000 - val_loss: 0.6002 - val_accuracy: 0.8405\n",
      "Epoch 72/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.8995 - val_loss: 0.5923 - val_accuracy: 0.8410\n",
      "Epoch 73/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9006 - val_loss: 0.5851 - val_accuracy: 0.8405\n",
      "Epoch 74/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9049 - val_loss: 0.6087 - val_accuracy: 0.8450\n",
      "Epoch 75/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9004 - val_loss: 0.5797 - val_accuracy: 0.8320\n",
      "Epoch 76/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9009 - val_loss: 0.5877 - val_accuracy: 0.8335\n",
      "Epoch 77/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2089 - accuracy: 0.9032 - val_loss: 0.6372 - val_accuracy: 0.8390\n",
      "Epoch 78/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9016 - val_loss: 0.6359 - val_accuracy: 0.8365\n",
      "Epoch 79/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9009 - val_loss: 0.6674 - val_accuracy: 0.8425\n",
      "Epoch 80/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9004 - val_loss: 0.6100 - val_accuracy: 0.8345\n",
      "Epoch 81/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9018 - val_loss: 0.7079 - val_accuracy: 0.8465\n",
      "Epoch 82/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9034 - val_loss: 0.7004 - val_accuracy: 0.8370\n",
      "Epoch 83/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2103 - accuracy: 0.9028 - val_loss: 0.6405 - val_accuracy: 0.8390\n",
      "Epoch 84/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9031 - val_loss: 0.6477 - val_accuracy: 0.8450\n",
      "Epoch 85/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9025 - val_loss: 0.7097 - val_accuracy: 0.8395\n",
      "Epoch 86/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9028 - val_loss: 0.6452 - val_accuracy: 0.8325\n",
      "Epoch 87/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2045 - accuracy: 0.9022 - val_loss: 0.6849 - val_accuracy: 0.8385\n",
      "Epoch 88/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9049 - val_loss: 0.6714 - val_accuracy: 0.8425\n",
      "Epoch 89/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9026 - val_loss: 0.7043 - val_accuracy: 0.8390\n",
      "Epoch 90/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9065 - val_loss: 0.6783 - val_accuracy: 0.8415\n",
      "Epoch 91/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9046 - val_loss: 0.6886 - val_accuracy: 0.8360\n",
      "Epoch 92/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2012 - accuracy: 0.9031 - val_loss: 0.6650 - val_accuracy: 0.8355\n",
      "Epoch 93/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9025 - val_loss: 0.6789 - val_accuracy: 0.8355\n",
      "Epoch 94/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9018 - val_loss: 0.6622 - val_accuracy: 0.8415\n",
      "Epoch 95/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9056 - val_loss: 0.7343 - val_accuracy: 0.8395\n",
      "Epoch 96/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9036 - val_loss: 0.7020 - val_accuracy: 0.8390\n",
      "Epoch 97/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9045 - val_loss: 0.7243 - val_accuracy: 0.8200\n",
      "Epoch 98/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9060 - val_loss: 0.6864 - val_accuracy: 0.8275\n",
      "Epoch 99/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9038 - val_loss: 0.6583 - val_accuracy: 0.8420\n",
      "Epoch 100/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9071 - val_loss: 0.7152 - val_accuracy: 0.8435\n",
      "Epoch 101/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9075 - val_loss: 0.7044 - val_accuracy: 0.8395\n",
      "Epoch 102/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9065 - val_loss: 0.7039 - val_accuracy: 0.8370\n",
      "Epoch 103/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9039 - val_loss: 0.7008 - val_accuracy: 0.8345\n",
      "Epoch 104/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9061 - val_loss: 0.7292 - val_accuracy: 0.8400\n",
      "Epoch 105/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9053 - val_loss: 0.7541 - val_accuracy: 0.8425\n",
      "Epoch 106/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9050 - val_loss: 0.7587 - val_accuracy: 0.8305\n",
      "Epoch 107/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9062 - val_loss: 0.6825 - val_accuracy: 0.8340\n",
      "Epoch 108/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9024 - val_loss: 0.7427 - val_accuracy: 0.8300\n",
      "Epoch 109/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9080 - val_loss: 0.7879 - val_accuracy: 0.8330\n",
      "Epoch 110/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9031 - val_loss: 0.7307 - val_accuracy: 0.8335\n",
      "Epoch 111/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9095 - val_loss: 0.8071 - val_accuracy: 0.8370\n",
      "Epoch 112/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.9076 - val_loss: 0.8234 - val_accuracy: 0.8300\n",
      "Epoch 113/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9082 - val_loss: 0.7413 - val_accuracy: 0.8370\n",
      "Epoch 114/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9074 - val_loss: 0.7824 - val_accuracy: 0.8350\n",
      "Epoch 115/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9091 - val_loss: 0.7785 - val_accuracy: 0.8260\n",
      "Epoch 116/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9039 - val_loss: 0.7731 - val_accuracy: 0.8305\n",
      "Epoch 117/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1975 - accuracy: 0.9051 - val_loss: 0.7911 - val_accuracy: 0.8390\n",
      "Epoch 118/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9090 - val_loss: 0.7802 - val_accuracy: 0.8340\n",
      "Epoch 119/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9115 - val_loss: 0.8026 - val_accuracy: 0.8310\n",
      "Epoch 120/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9101 - val_loss: 0.8098 - val_accuracy: 0.8295\n",
      "Epoch 121/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.9124 - val_loss: 0.8012 - val_accuracy: 0.8330\n",
      "Epoch 122/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.9120 - val_loss: 0.8375 - val_accuracy: 0.8385\n",
      "Epoch 123/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.9104 - val_loss: 0.8314 - val_accuracy: 0.8365\n",
      "Epoch 124/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9080 - val_loss: 0.7919 - val_accuracy: 0.8265\n",
      "Epoch 125/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9060 - val_loss: 0.7733 - val_accuracy: 0.8305\n",
      "Epoch 126/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.9093 - val_loss: 0.8012 - val_accuracy: 0.8325\n",
      "Epoch 127/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.9114 - val_loss: 0.8270 - val_accuracy: 0.8400\n",
      "Epoch 128/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9105 - val_loss: 0.8072 - val_accuracy: 0.8120\n",
      "Epoch 129/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9100 - val_loss: 0.8409 - val_accuracy: 0.8375\n",
      "Epoch 130/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9086 - val_loss: 0.8565 - val_accuracy: 0.8390\n",
      "Epoch 131/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9111 - val_loss: 0.8337 - val_accuracy: 0.8415\n",
      "Epoch 132/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9081 - val_loss: 0.8732 - val_accuracy: 0.8395\n",
      "Epoch 133/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9065 - val_loss: 0.8378 - val_accuracy: 0.8340\n",
      "Epoch 134/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9106 - val_loss: 0.8576 - val_accuracy: 0.8320\n",
      "Epoch 135/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9101 - val_loss: 0.8719 - val_accuracy: 0.8365\n",
      "Epoch 136/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9106 - val_loss: 0.8557 - val_accuracy: 0.8295\n",
      "Epoch 137/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.9079 - val_loss: 0.8384 - val_accuracy: 0.8320\n",
      "Epoch 138/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9116 - val_loss: 0.9112 - val_accuracy: 0.8330\n",
      "Epoch 139/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9071 - val_loss: 0.9011 - val_accuracy: 0.8245\n",
      "Epoch 140/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9130 - val_loss: 0.8410 - val_accuracy: 0.8120\n",
      "Epoch 141/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9119 - val_loss: 0.9038 - val_accuracy: 0.8140\n",
      "Epoch 142/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.9120 - val_loss: 0.9128 - val_accuracy: 0.8345\n",
      "Epoch 143/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9103 - val_loss: 0.8996 - val_accuracy: 0.8345\n",
      "Epoch 144/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9101 - val_loss: 0.8447 - val_accuracy: 0.8295\n",
      "Epoch 145/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9097 - val_loss: 0.8921 - val_accuracy: 0.8350\n",
      "Epoch 146/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.9129 - val_loss: 0.9061 - val_accuracy: 0.8340\n",
      "Epoch 147/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9095 - val_loss: 0.8555 - val_accuracy: 0.8310\n",
      "Epoch 148/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9153 - val_loss: 0.9448 - val_accuracy: 0.8345\n",
      "Epoch 149/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9110 - val_loss: 0.8468 - val_accuracy: 0.8285\n",
      "Epoch 150/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9115 - val_loss: 0.9015 - val_accuracy: 0.8375\n",
      "Epoch 151/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.9114 - val_loss: 0.9021 - val_accuracy: 0.8330\n",
      "Epoch 152/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.9114 - val_loss: 0.8824 - val_accuracy: 0.8085\n",
      "Epoch 153/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9121 - val_loss: 0.9232 - val_accuracy: 0.8110\n",
      "Epoch 154/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9154 - val_loss: 0.8886 - val_accuracy: 0.8280\n",
      "Epoch 155/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9107 - val_loss: 0.8962 - val_accuracy: 0.8340\n",
      "Epoch 156/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9118 - val_loss: 0.9394 - val_accuracy: 0.8315\n",
      "Epoch 157/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9119 - val_loss: 1.0214 - val_accuracy: 0.8320\n",
      "Epoch 158/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9116 - val_loss: 0.9887 - val_accuracy: 0.8310\n",
      "Epoch 159/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9160 - val_loss: 0.9781 - val_accuracy: 0.8250\n",
      "Epoch 160/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1724 - accuracy: 0.9101 - val_loss: 0.9674 - val_accuracy: 0.8255\n",
      "Epoch 161/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.9116 - val_loss: 0.9858 - val_accuracy: 0.8300\n",
      "Epoch 162/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.9124 - val_loss: 1.0217 - val_accuracy: 0.8330\n",
      "Epoch 163/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9124 - val_loss: 0.9641 - val_accuracy: 0.8340\n",
      "Epoch 164/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9141 - val_loss: 0.9607 - val_accuracy: 0.8050\n",
      "Epoch 165/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.9131 - val_loss: 1.0232 - val_accuracy: 0.8285\n",
      "Epoch 166/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9131 - val_loss: 0.9823 - val_accuracy: 0.8355\n",
      "Epoch 167/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9140 - val_loss: 0.9878 - val_accuracy: 0.8355\n",
      "Epoch 168/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9109 - val_loss: 0.9837 - val_accuracy: 0.8340\n",
      "Epoch 169/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9131 - val_loss: 1.0325 - val_accuracy: 0.8390\n",
      "Epoch 170/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9158 - val_loss: 1.0559 - val_accuracy: 0.8345\n",
      "Epoch 171/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9121 - val_loss: 0.9752 - val_accuracy: 0.8345\n",
      "Epoch 172/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9118 - val_loss: 1.0163 - val_accuracy: 0.8290\n",
      "Epoch 173/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9164 - val_loss: 1.0477 - val_accuracy: 0.8320\n",
      "Epoch 174/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9111 - val_loss: 0.9532 - val_accuracy: 0.8340\n",
      "Epoch 175/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9159 - val_loss: 1.0146 - val_accuracy: 0.8365\n",
      "Epoch 176/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9184 - val_loss: 1.0804 - val_accuracy: 0.8085\n",
      "Epoch 177/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1568 - accuracy: 0.9209 - val_loss: 1.1322 - val_accuracy: 0.8140\n",
      "Epoch 178/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9162 - val_loss: 1.0930 - val_accuracy: 0.8305\n",
      "Epoch 179/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.9086 - val_loss: 0.9627 - val_accuracy: 0.8385\n",
      "Epoch 180/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9106 - val_loss: 0.9494 - val_accuracy: 0.8335\n",
      "Epoch 181/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1678 - accuracy: 0.9155 - val_loss: 0.9515 - val_accuracy: 0.8295\n",
      "Epoch 182/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1641 - accuracy: 0.9168 - val_loss: 1.0356 - val_accuracy: 0.8280\n",
      "Epoch 183/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9147 - val_loss: 0.9966 - val_accuracy: 0.8340\n",
      "Epoch 184/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9135 - val_loss: 1.0269 - val_accuracy: 0.8035\n",
      "Epoch 185/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9133 - val_loss: 1.0415 - val_accuracy: 0.8265\n",
      "Epoch 186/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9128 - val_loss: 1.0518 - val_accuracy: 0.8360\n",
      "Epoch 187/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9165 - val_loss: 1.0162 - val_accuracy: 0.7975\n",
      "Epoch 188/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9160 - val_loss: 1.0997 - val_accuracy: 0.8055\n",
      "Epoch 189/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9161 - val_loss: 1.0682 - val_accuracy: 0.7910\n",
      "Epoch 190/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9129 - val_loss: 1.0698 - val_accuracy: 0.8030\n",
      "Epoch 191/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1696 - accuracy: 0.9144 - val_loss: 1.0852 - val_accuracy: 0.8270\n",
      "Epoch 192/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1701 - accuracy: 0.9135 - val_loss: 1.0710 - val_accuracy: 0.7915\n",
      "Epoch 193/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9186 - val_loss: 1.0845 - val_accuracy: 0.7980\n",
      "Epoch 194/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9151 - val_loss: 1.0655 - val_accuracy: 0.8330\n",
      "Epoch 195/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9153 - val_loss: 1.1135 - val_accuracy: 0.8280\n",
      "Epoch 196/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9170 - val_loss: 1.0762 - val_accuracy: 0.8345\n",
      "Epoch 197/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9166 - val_loss: 1.1133 - val_accuracy: 0.8215\n",
      "Epoch 198/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1637 - accuracy: 0.9176 - val_loss: 1.1216 - val_accuracy: 0.8045\n",
      "Epoch 199/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1594 - accuracy: 0.9202 - val_loss: 1.0956 - val_accuracy: 0.8025\n",
      "Epoch 200/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9187 - val_loss: 1.1259 - val_accuracy: 0.8035\n",
      "Epoch 201/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1710 - accuracy: 0.9153 - val_loss: 1.1271 - val_accuracy: 0.8040\n",
      "Epoch 202/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9162 - val_loss: 1.0941 - val_accuracy: 0.8165\n",
      "Epoch 203/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1643 - accuracy: 0.9202 - val_loss: 1.1489 - val_accuracy: 0.8095\n",
      "Epoch 204/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1666 - accuracy: 0.9156 - val_loss: 1.0764 - val_accuracy: 0.8070\n",
      "Epoch 205/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9190 - val_loss: 1.1079 - val_accuracy: 0.8280\n",
      "Epoch 206/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1614 - accuracy: 0.9196 - val_loss: 1.0917 - val_accuracy: 0.8030\n",
      "Epoch 207/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9226 - val_loss: 1.0957 - val_accuracy: 0.7915\n",
      "Epoch 208/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9183 - val_loss: 1.0625 - val_accuracy: 0.8355\n",
      "Epoch 209/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9154 - val_loss: 1.0847 - val_accuracy: 0.8130\n",
      "Epoch 210/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9195 - val_loss: 1.1252 - val_accuracy: 0.8175\n",
      "Epoch 211/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1487 - accuracy: 0.9240 - val_loss: 1.1256 - val_accuracy: 0.8130\n",
      "Epoch 212/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1492 - accuracy: 0.9234 - val_loss: 1.1912 - val_accuracy: 0.8070\n",
      "Epoch 213/300\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9215 - val_loss: 1.1751 - val_accuracy: 0.7985\n",
      "Epoch 214/300\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9190 - val_loss: 1.1442 - val_accuracy: 0.8005\n",
      "Epoch 215/300\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.9210 - val_loss: 1.1778 - val_accuracy: 0.8020\n",
      "Epoch 216/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9162 - val_loss: 1.0998 - val_accuracy: 0.8060\n",
      "Epoch 217/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9225 - val_loss: 1.1846 - val_accuracy: 0.8015\n",
      "Epoch 218/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9221 - val_loss: 1.1795 - val_accuracy: 0.8285\n",
      "Epoch 219/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9206 - val_loss: 1.1648 - val_accuracy: 0.8055\n",
      "Epoch 220/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9183 - val_loss: 1.1014 - val_accuracy: 0.8335\n",
      "Epoch 221/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9194 - val_loss: 1.1078 - val_accuracy: 0.8025\n",
      "Epoch 222/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1545 - accuracy: 0.9245 - val_loss: 1.1319 - val_accuracy: 0.8045\n",
      "Epoch 223/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1516 - accuracy: 0.9226 - val_loss: 1.1277 - val_accuracy: 0.7950\n",
      "Epoch 224/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1503 - accuracy: 0.9226 - val_loss: 1.2079 - val_accuracy: 0.8045\n",
      "Epoch 225/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9195 - val_loss: 1.1557 - val_accuracy: 0.8055\n",
      "Epoch 226/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1534 - accuracy: 0.9245 - val_loss: 1.3037 - val_accuracy: 0.8015\n",
      "Epoch 227/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9240 - val_loss: 1.2722 - val_accuracy: 0.7965\n",
      "Epoch 228/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9226 - val_loss: 1.1674 - val_accuracy: 0.7935\n",
      "Epoch 229/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9158 - val_loss: 1.2190 - val_accuracy: 0.8045\n",
      "Epoch 230/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1614 - accuracy: 0.9199 - val_loss: 1.2222 - val_accuracy: 0.7950\n",
      "Epoch 231/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9160 - val_loss: 1.1625 - val_accuracy: 0.7980\n",
      "Epoch 232/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9209 - val_loss: 1.1815 - val_accuracy: 0.7955\n",
      "Epoch 233/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1531 - accuracy: 0.9244 - val_loss: 1.2062 - val_accuracy: 0.8025\n",
      "Epoch 234/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9236 - val_loss: 1.2231 - val_accuracy: 0.8015\n",
      "Epoch 235/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9212 - val_loss: 1.2250 - val_accuracy: 0.7970\n",
      "Epoch 236/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9189 - val_loss: 1.2394 - val_accuracy: 0.8075\n",
      "Epoch 237/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1590 - accuracy: 0.9201 - val_loss: 1.1899 - val_accuracy: 0.7980\n",
      "Epoch 238/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9237 - val_loss: 1.2297 - val_accuracy: 0.8000\n",
      "Epoch 239/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9234 - val_loss: 1.3024 - val_accuracy: 0.8105\n",
      "Epoch 240/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9206 - val_loss: 1.2532 - val_accuracy: 0.8020\n",
      "Epoch 241/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9212 - val_loss: 1.2202 - val_accuracy: 0.8350\n",
      "Epoch 242/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9158 - val_loss: 1.2508 - val_accuracy: 0.8070\n",
      "Epoch 243/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9249 - val_loss: 1.2543 - val_accuracy: 0.7975\n",
      "Epoch 244/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1535 - accuracy: 0.9252 - val_loss: 1.3000 - val_accuracy: 0.8015\n",
      "Epoch 245/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9195 - val_loss: 1.1554 - val_accuracy: 0.8080\n",
      "Epoch 246/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9164 - val_loss: 1.1797 - val_accuracy: 0.8325\n",
      "Epoch 247/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1483 - accuracy: 0.9250 - val_loss: 1.2769 - val_accuracy: 0.8090\n",
      "Epoch 248/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9289 - val_loss: 1.2681 - val_accuracy: 0.8020\n",
      "Epoch 249/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9210 - val_loss: 1.1263 - val_accuracy: 0.7960\n",
      "Epoch 250/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1607 - accuracy: 0.9224 - val_loss: 1.1685 - val_accuracy: 0.7995\n",
      "Epoch 251/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1592 - accuracy: 0.9216 - val_loss: 1.2178 - val_accuracy: 0.8090\n",
      "Epoch 252/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9246 - val_loss: 1.2311 - val_accuracy: 0.8035\n",
      "Epoch 253/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9240 - val_loss: 1.2987 - val_accuracy: 0.7985\n",
      "Epoch 254/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9264 - val_loss: 1.2115 - val_accuracy: 0.8010\n",
      "Epoch 255/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1551 - accuracy: 0.9246 - val_loss: 1.2812 - val_accuracy: 0.8020\n",
      "Epoch 256/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9205 - val_loss: 1.2257 - val_accuracy: 0.8005\n",
      "Epoch 257/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9247 - val_loss: 1.2982 - val_accuracy: 0.7910\n",
      "Epoch 258/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9254 - val_loss: 1.3073 - val_accuracy: 0.8005\n",
      "Epoch 259/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9226 - val_loss: 1.2781 - val_accuracy: 0.7885\n",
      "Epoch 260/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9277 - val_loss: 1.2731 - val_accuracy: 0.8025\n",
      "Epoch 261/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1467 - accuracy: 0.9258 - val_loss: 1.2916 - val_accuracy: 0.8010\n",
      "Epoch 262/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9234 - val_loss: 1.2771 - val_accuracy: 0.8040\n",
      "Epoch 263/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1448 - accuracy: 0.9255 - val_loss: 1.3830 - val_accuracy: 0.8015\n",
      "Epoch 264/300\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9225 - val_loss: 1.2901 - val_accuracy: 0.8010\n",
      "Epoch 265/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1492 - accuracy: 0.9233 - val_loss: 1.3667 - val_accuracy: 0.7860\n",
      "Epoch 266/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9234 - val_loss: 1.3485 - val_accuracy: 0.8000\n",
      "Epoch 267/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9197 - val_loss: 1.3781 - val_accuracy: 0.8055\n",
      "Epoch 268/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1570 - accuracy: 0.9259 - val_loss: 1.3231 - val_accuracy: 0.8050\n",
      "Epoch 269/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9290 - val_loss: 1.2969 - val_accuracy: 0.8025\n",
      "Epoch 270/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9306 - val_loss: 1.3522 - val_accuracy: 0.8040\n",
      "Epoch 271/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1535 - accuracy: 0.9243 - val_loss: 1.2793 - val_accuracy: 0.7980\n",
      "Epoch 272/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9162 - val_loss: 1.2305 - val_accuracy: 0.7945\n",
      "Epoch 273/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1453 - accuracy: 0.9264 - val_loss: 1.3768 - val_accuracy: 0.8070\n",
      "Epoch 274/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9301 - val_loss: 1.4091 - val_accuracy: 0.7970\n",
      "Epoch 275/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9293 - val_loss: 1.3385 - val_accuracy: 0.7980\n",
      "Epoch 276/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9271 - val_loss: 1.2906 - val_accuracy: 0.8020\n",
      "Epoch 277/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1509 - accuracy: 0.9247 - val_loss: 1.3725 - val_accuracy: 0.7990\n",
      "Epoch 278/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9269 - val_loss: 1.3178 - val_accuracy: 0.7910\n",
      "Epoch 279/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1522 - accuracy: 0.9250 - val_loss: 1.4182 - val_accuracy: 0.8005\n",
      "Epoch 280/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9199 - val_loss: 1.3619 - val_accuracy: 0.8060\n",
      "Epoch 281/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1488 - accuracy: 0.9250 - val_loss: 1.3245 - val_accuracy: 0.8020\n",
      "Epoch 282/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9299 - val_loss: 1.3994 - val_accuracy: 0.8000\n",
      "Epoch 283/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9279 - val_loss: 1.3073 - val_accuracy: 0.7985\n",
      "Epoch 284/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9224 - val_loss: 1.3816 - val_accuracy: 0.8130\n",
      "Epoch 285/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9209 - val_loss: 1.2470 - val_accuracy: 0.7960\n",
      "Epoch 286/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1415 - accuracy: 0.9275 - val_loss: 1.3599 - val_accuracy: 0.7880\n",
      "Epoch 287/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9315 - val_loss: 1.3660 - val_accuracy: 0.7965\n",
      "Epoch 288/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1340 - accuracy: 0.9324 - val_loss: 1.4552 - val_accuracy: 0.8060\n",
      "Epoch 289/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9262 - val_loss: 1.3317 - val_accuracy: 0.7980\n",
      "Epoch 290/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9222 - val_loss: 1.3703 - val_accuracy: 0.7975\n",
      "Epoch 291/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9262 - val_loss: 1.3546 - val_accuracy: 0.7995\n",
      "Epoch 292/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1372 - accuracy: 0.9301 - val_loss: 1.3473 - val_accuracy: 0.7845\n",
      "Epoch 293/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9312 - val_loss: 1.4818 - val_accuracy: 0.7980\n",
      "Epoch 294/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9284 - val_loss: 1.3735 - val_accuracy: 0.7940\n",
      "Epoch 295/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1708 - accuracy: 0.9172 - val_loss: 1.2246 - val_accuracy: 0.8075\n",
      "Epoch 296/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9261 - val_loss: 1.3656 - val_accuracy: 0.7985\n",
      "Epoch 297/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9255 - val_loss: 1.3200 - val_accuracy: 0.7995\n",
      "Epoch 298/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9244 - val_loss: 1.3759 - val_accuracy: 0.8040\n",
      "Epoch 299/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.9279 - val_loss: 1.3972 - val_accuracy: 0.7955\n",
      "Epoch 300/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9316 - val_loss: 1.4276 - val_accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "history=model.fit(\n",
    "    X_train,y_train,validation_data=(X_test,y_test),epochs=300,\n",
    "    callbacks=[tensorflow_callback,early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "## Load Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit/20250803-145840/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the pickle file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
